## Optimal mix in heterogeneous ensemble learner (2019, KU Leuven)

<h2>Abstract</h2>

In the telecommunication industry, churn prediction is an important topic in customer relationship management. Ensemble learners combine individual classifiers to increase the predictive performance. In order to discover the optimal mix of base classifiers, 210 different heterogeneous ensembles were created and evaluated. The combination of an Artificial Neural Network, a Decision Tree and Gradient Boosted Trees can be identified as the optimal mix for both, ensembles size three and five. It is approved that heterogeneous ensembles out perform homogeneous ensembles. The inclusion of individually well performing classifiers in an ensemble leads to strong ensemble performance. The bigger the ensemble, the higher the probability for a strong performing ensemble learner, however the top performing classifier is composed out of just three base classifier.


<h2>Ressources</h2>

- <b>[Read Full Research](https://github.com/raphaelhanke/master_thesis_ensembles/blob/main/Master_Thesis.pdf)
- [Source Code](https://github.com/raphaelhanke/master_thesis_ensembles/tree/main/source%20codes) </b>

<h2>Credits</h2>

The research has been conducted during the Master Program "Information Management" and in collaboration with the Research Centre for Information Systems Engineering (LIRIS) of KU LEUVEN.


<img src="https://drive.google.com/uc?id=1gQmYBb0UviMl2h9hD1tgYQWm7RUewbY9" height="20%" width="20%" alt="KU LEUVEN"/> 
